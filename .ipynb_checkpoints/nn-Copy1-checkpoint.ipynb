{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "# TODO: env = states of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns only one action\n",
    "def softmax_activate(layer):\n",
    "    m = np.exp(layer)\n",
    "    return m/m.sum(len(m.shape)-1)\n",
    "\n",
    "# sigmoid returns more than one action\n",
    "def sigmoid_activate(layer):  \n",
    "    return 1 / (1+np.exp(-layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layers = 3\n",
    "neurons = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, observation_size): #We specify the observation\n",
    "        self._layers = []\n",
    "        self._biases = [] #we implement the biases\n",
    "        \n",
    "        for i in range(nb_layers):\n",
    "           \n",
    "            entry_size = neurons if i != 0 else observation_size #First layer must match the input layer.\n",
    "                                                                #Remember : The input layer is all the map, flattened.\n",
    "            \n",
    "            \n",
    "            #our weights values will be from -1 to 1.\n",
    "            self._layers.append(np.random.rand(neurons,entry_size)*2-1) #we initialize random values\n",
    "            self._biases.append(np.random.rand(neurons, 1)*2-1) #we initialize random values.\n",
    "        \n",
    "\n",
    "        self._outputs = np.random.rand(4,neurons)*2-1 #Output layer must contain a total of 4 cells.\n",
    "        #We don't add it into self._layers because we want to activate it with a softmax.\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        inputs = inputs.reshape((-1,1))\n",
    "        \n",
    "        \n",
    "\n",
    "        for layer, bias in zip(self._layers, self._biases): #we zip the biases to the layer\n",
    "            \n",
    "            inputs = np.matmul(layer,inputs)\n",
    "            inputs = inputs+bias\n",
    "            inputs = sigmoid_activate(inputs)\n",
    "            \n",
    "        inputs = np.matmul(self._outputs, inputs) #(4,1)\n",
    "        inputs = inputs.reshape(-1) #Just a vector of 4 elements.\n",
    "        \n",
    "        \n",
    "        return softmax_activate(inputs)#Updated to softmax\n",
    "\n",
    "    def mutate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIT_WALL_PENALTY = -1\n",
    "PLAYER_SPEED = 44\n",
    "EXIT_REWARD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def calc_goal_dist(x1,y1,x2,y2, m=\"manhattan\"):\n",
    "    if m == \"euclidean\":\n",
    "        goal_dist = sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    elif m==\"manhattan\":\n",
    "        goal_dist = int(abs(abs(x2) - abs(x1))/PLAYER_SPEED + abs(abs(y2) - abs(y1))/PLAYER_SPEED)\n",
    "\n",
    "    return goal_dist\n",
    "\n",
    "def calc_what_move(old_pos, new_pos):\n",
    "    diff = [old_pos[i] - new_pos[i] for i in range(len(old_pos))]\n",
    "\n",
    "    if diff[0] < 0:\n",
    "        return \"right\"\n",
    "    elif diff[0] > 0:\n",
    "        return \"left\"\n",
    "    elif diff[1] < 0:\n",
    "        return \"down\"\n",
    "    elif diff[1] > 0:\n",
    "        return \"up\"\n",
    "    elif diff[0] == 0 and diff[1] == 0:\n",
    "        return\n",
    "    else:\n",
    "        print(\"MISTAKES WERE MADE! IDK WHAT'S GOING ON\")\n",
    "        print(\"old pos {}, new pos {}\".format(old_pos, new_pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "class env():\n",
    "    def __init__(self, states):\n",
    "       \n",
    "        self.row = len(states)-1\n",
    "        self.col = len(states[0])-1\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        r,c = generate(5,0)\n",
    "        return to_matrix(r,c)\n",
    "    \n",
    "    # to prevent index errors\n",
    "    def legal_move(self, action, states):\n",
    "       \n",
    "        coord = np.where(states == 2)\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "       \n",
    "        #0: right, 1:left, 2:up, 3:down\n",
    "       \n",
    "        #=======================================\n",
    "        if action == 0:\n",
    "           \n",
    "            # find where the agent is, index 0 means row: U/D, 1 means col: R/L\n",
    "            # if hit wall, then minus reward\n",
    "            if states[coord[0],coord[1]+1] == 1.0:\n",
    "                \n",
    "                reward += HIT_WALL_PENALTY\n",
    "                done = True\n",
    "            elif states[coord[0],coord[1]+1] == 5.0:\n",
    "                \n",
    "                states[coord[0],coord[1]+1] = 2.0\n",
    "                states[coord] = 0.0\n",
    "                done = True\n",
    "                reward += EXIT_REWARD\n",
    "            else:\n",
    "              \n",
    "                states[coord[0],coord[1]+1] = 2.0\n",
    "               \n",
    "                states[coord[0],coord[1]] = 0.0\n",
    "                \n",
    "                \n",
    "            \n",
    "        if action == 1:\n",
    "           \n",
    "            if states[coord[0],coord[1]-1] == 1.0:\n",
    "                \n",
    "                reward += HIT_WALL_PENALTY\n",
    "                done = True\n",
    "            elif states[coord[0],coord[1]-1] == 5.0:\n",
    "                \n",
    "                states[coord[0],coord[1]-1] = 2.0\n",
    "                states[coord] = 0.0\n",
    "                done = True\n",
    "                reward += EXIT_REWARD\n",
    "            else:\n",
    "              \n",
    "                states[coord[0],coord[1]-1] = 2.0\n",
    "               \n",
    "                states[coord[0],coord[1]] = 0.0\n",
    "           \n",
    "        if action == 2:\n",
    "            if states[coord[0]-1,coord[1]] == 1.0:\n",
    "                \n",
    "                reward += HIT_WALL_PENALTY\n",
    "                done = True\n",
    "            elif states[coord[0]-1,coord[1]] == 5.0:\n",
    "                \n",
    "                states[coord[0]-1,coord[1]] = 2.0\n",
    "                states[coord] = 0.0\n",
    "                done = True\n",
    "                reward += EXIT_REWARD\n",
    "            else:\n",
    "              \n",
    "                states[coord[0]-1,coord[1]] = 2.0\n",
    "               \n",
    "                states[coord[0],coord[1]] = 0.0\n",
    "                \n",
    "        if action == 3:\n",
    "           \n",
    "            if states[coord[0]+1,coord[1]] == 1.0:\n",
    "                \n",
    "                reward += HIT_WALL_PENALTY\n",
    "                done = True\n",
    "            elif states[coord[0]+1,coord[1]] == 5.0:\n",
    "                \n",
    "                states[coord[0]-1,coord[1]] = 2.0\n",
    "                states[coord] = 0.0\n",
    "                done = True\n",
    "                reward += EXIT_REWARD\n",
    "            else:\n",
    "              \n",
    "                states[coord[0]+1,coord[1]] = 2.0\n",
    "               \n",
    "                states[coord[0],coord[1]] = 0.0\n",
    "            \n",
    "       \n",
    "       # TODO: add 4 back\n",
    "       \n",
    "        return states, reward, done, info\n",
    "                \n",
    "        \n",
    "    def step(self, a, s):\n",
    "        action = a\n",
    "        state = s\n",
    "       \n",
    "        return self.legal_move(action,state)\n",
    "       \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class to generate random mazes of some nxn dimensions\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "rows = []\n",
    "columns = []\n",
    "cells = []\n",
    "walls = 0\n",
    "saved_mazes = []\n",
    "\n",
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "    def isEmpty(self):\n",
    "        return self.items == []\n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "    def peek(self):\n",
    "        return self.items[len(self.items)-1]\n",
    "    def size(self):\n",
    "        return len(self.items)\n",
    "\n",
    "class MazeCell:\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.visited = False\n",
    "\n",
    "#generate a random maze\n",
    "def generate(maze_size, trial):\n",
    "\n",
    "\tglobal walls\n",
    "\tglobal rows\n",
    "\tglobal columns\n",
    "\tglobal cells\n",
    "\n",
    "\t\n",
    "\n",
    "\twalls = maze_size\n",
    "\trows = [[1 for i in range(walls)] for j in range(walls+1)]\n",
    "\tcolumns = [[1 for i in range(walls+1)] for j in range(walls)]\n",
    "\n",
    "\t# Create the cells that shows visited or not\n",
    "\tfor y in range(walls):\n",
    "\t\tfor x in range(walls):\n",
    "\t\t\tcells.append(MazeCell(x,y))\n",
    "\n",
    "\tcell_stack = Stack()\n",
    "\tunvistedCells = len(cells)\n",
    "\tcurrentCell = 0\n",
    "\tcells[currentCell].visited = True\n",
    "\tunvistedCells -= 1\n",
    "\n",
    "\t#While there are unvisited cells\n",
    "\twhile (unvistedCells > 0):\n",
    "\t\tnextCell = chooseUnvisitedNeighbor(currentCell)\n",
    "\t\tif(nextCell != -1):\n",
    "\t\t\tcell_stack.push(currentCell)\n",
    "\t\t\t#remove the wall in between currentCell and nextCell\n",
    "\t\t\tremoveWall(currentCell,nextCell)\n",
    "\t\t\tcurrentCell = nextCell\n",
    "\t\t\tcells[currentCell].visited = True\n",
    "\t\t\tunvistedCells -= 1\n",
    "\t\telif(cell_stack.size() > 0):\n",
    "\t\t\tcurrentCell = cell_stack.pop()\n",
    "\n",
    "\tcells = [] #reset cells for when method is called again\n",
    "\n",
    "\treturn rows, columns\n",
    "\n",
    "def chooseUnvisitedNeighbor(currentCell):\n",
    "\tx = cells[currentCell].x\n",
    "\ty = cells[currentCell].y\n",
    "\n",
    "\tcandidates = []\n",
    "\n",
    "\t# left\n",
    "\tif(x > 0 and cells[currentCell-1].visited is False):\n",
    "\t\tcandidates.append(currentCell-1)\n",
    "\t# right\n",
    "\tif(x < (walls-1) and cells[currentCell+1].visited is False):\n",
    "\t\tcandidates.append(currentCell+1)\n",
    "\t# up\n",
    "\tif(y > 0 and cells[currentCell-walls].visited is False):\n",
    "\t\tcandidates.append(currentCell-walls)\n",
    "\t# down\n",
    "\tif(y < (walls-1) and cells[currentCell+walls].visited is False):\n",
    "\t\tcandidates.append(currentCell+walls)\n",
    "\n",
    "\tif(len(candidates) == 0):\n",
    "\t\t#print \"no choice\"\n",
    "\t\treturn -1\n",
    "\n",
    "\t#choose a random candidate\n",
    "\trandom_choice = random.sample(candidates,len(candidates))\n",
    "\t#print random_choice[0]\n",
    "\treturn random_choice[0]\n",
    "def removeWall(currentCell,nextCell):\n",
    "\n",
    "\tglobal columns\n",
    "\tglobal rows\n",
    "\n",
    "\t#remove column to the right of currentCell\n",
    "\tif(nextCell-currentCell == 1):\n",
    "\t\tcolumns[currentCell//walls][currentCell%walls+1] = 0\n",
    "\t\t#print \"right\"\n",
    "\t#remove column to the left of currentCell\n",
    "\telif(currentCell - nextCell == 1):\n",
    "\t\tcolumns[currentCell//walls][currentCell%walls] = 0\n",
    "\t\t#print \"left\"\n",
    "\t#remove row above currentCell\n",
    "\telif(currentCell - nextCell == walls):\n",
    "\t\trows[currentCell//walls][currentCell%walls] = 0\n",
    "\t\t#print \"up\"\n",
    "\t#remove row below currentCell\n",
    "\telif(nextCell - currentCell == walls):\n",
    "\t\trows[currentCell//walls+1][currentCell%walls] = 0\n",
    "\t\t#print \"down\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate positions of walls\n",
    "\n",
    "rows, columns = generate(5,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows\n",
    "e = env(m)\n",
    "observation = e.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 0., 1., 5., 1.],\n",
       "       [1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 2., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to matrix\n",
    "\n",
    "def to_matrix(rows, cols):\n",
    "    maze = np.zeros([11,11])\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        for j in range(len(rows[i])):\n",
    "            if rows[i][j] == 1:\n",
    "                maze[i*2][j*2] = 1\n",
    "                maze[i*2][j*2+1] = 1\n",
    "                maze[i*2][j*2+2] = 1\n",
    "\n",
    "    for i in range(len(cols[0])):\n",
    "\n",
    "        for j in range(len(cols)):\n",
    "            if cols[j][i] == 1:\n",
    "\n",
    "                maze[j*2][i*2] = 1\n",
    "                maze[j*2+1][i*2] = 1\n",
    "                maze[j*2+2][i*2] = 1\n",
    "\n",
    "    maze[1][9] = 5  # exit\n",
    "    maze[9][1] = 2  # starting point\n",
    "    return maze\n",
    "m = to_matrix(rows, columns)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "obs_size = m.shape[0]*m.shape[1]\n",
    "obs_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = NeuralNetwork(obs_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 2. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 2. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 2. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 2. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 2. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 2. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 2. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 2. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 2. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "0\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "oustide\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "reward:\n",
      "-1\n",
      "{}\n",
      "----\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 5. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import time #used to wait between each frame.\n",
    "e = env(m)\n",
    "observation = e.reset()#We get the first element of the game.\n",
    "#env.render() #We render it.\n",
    "\n",
    "done = False #While not True, the simulation runs.\n",
    "#0: right, 1:left, 2:up, 3:down\n",
    "        \n",
    "while(not done):\n",
    "    print('oustide')\n",
    "    print(observation)\n",
    "    c = Sample.forward(observation).argmax()\n",
    "    observation, reward, done, info = e.step(c, observation) #We exectue an action.\n",
    "    #env.render() #We tell gym we want to render.\n",
    "    print(\"reward:\")\n",
    "    print(reward)\n",
    "    print(info)\n",
    "    print(\"----\")\n",
    "    print(observation)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, observation_size):\n",
    "        self._rewards = 0 #Number of registered rewards.\n",
    "        self._layers = []\n",
    "        self._biases = []\n",
    "        \n",
    "        for i in range(nb_layers):\n",
    "            entry_size = neurons if i != 0 else observation_size\n",
    "            self._layers.append(np.random.rand(neurons,entry_size)*2-1)\n",
    "            self._biases.append(np.random.rand(neurons,1)*2-1)\n",
    "        \n",
    "\n",
    "        self._outputs = np.random.rand(4,neurons)*2-1\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.reshape((-1,1))\n",
    "        \n",
    "\n",
    "        for layer, bias in zip(self._layers, self._biases):\n",
    "            inputs = np.matmul(layer,inputs)\n",
    "            inputs = inputs+bias\n",
    "            inputs = sigmoid_activate(inputs)\n",
    "            \n",
    "        inputs = np.matmul(self._outputs, inputs)\n",
    "        inputs = inputs.reshape(-1)\n",
    "        \n",
    "        \n",
    "        return softmax_activate(inputs)\n",
    "\n",
    "    def mutate(self): #TODO\n",
    "        pass\n",
    "    \n",
    "    def set_reward(self, r): #We register the reward it got.\n",
    "        self._reward = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(chicken, nb_of_simulations=10):\n",
    "    \n",
    "    total_reward = 0 #Used to track the performance of the Snake.\n",
    "   \n",
    "    for _ in range(nb_of_simulations):\n",
    "    \n",
    "        observation = e.reset()\n",
    "       \n",
    "        done = False\n",
    "        #0: right, 1:left, 2:up, 3:down\n",
    "       \n",
    "        while(not done):\n",
    "            \n",
    "            a = chicken.forward(observation).argmax()\n",
    "            \n",
    "            observation, reward, done, info = e.step(a, observation) #We exectue an action.\n",
    "            #env.render() #We DO NOT CALL RENDER HERE, we now need speed!\n",
    "            print(reward)\n",
    "            total_reward += reward\n",
    "    \n",
    "    chicken.set_reward(total_reward)\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_chicken = 10\n",
    "farm = []\n",
    "for _ in range(number_of_chicken):\n",
    "    S = NeuralNetwork(obs_size)\n",
    "    farm.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for S in farm:\n",
    "    rewards.append(run_simulation(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10, -10, -10, -10, -10, -10, -10, -10, -10, -10]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rewards, bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_saved = 0.1 #percentage of snakes which will be removed because they performance are too low\n",
    "chances_of_mutation = 1e-2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst score was -10; best score was-10\n"
     ]
    }
   ],
   "source": [
    "farm.sort(key=lambda snake: snake._reward, reverse=True) \n",
    "print(\"Worst score was \"+str(farm[-1]._reward)+\"; best score was\"+str(farm[0]._reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, observation_size, isACopy=False): #We add the isACopy to track the copy of layers.\n",
    "        self._rewards = 0\n",
    "        self._layers = []\n",
    "        self._biases = []\n",
    "        \n",
    "        if(not isACopy):\n",
    "            for i in range(nb_layers):\n",
    "                entry_size = neurons if i != 0 else observation_size\n",
    "                self._layers.append(np.random.rand(neurons,entry_size)*2-1)\n",
    "                self._biases.append(np.random.rand(neurons,1)*2-1)\n",
    "\n",
    "\n",
    "            self._outputs = np.random.rand(4,neurons)*2-1\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.reshape((-1,1))\n",
    "        \n",
    "\n",
    "        for layer, bias in zip(self._layers, self._biases):\n",
    "            inputs = np.matmul(layer,inputs)\n",
    "            inputs = inputs+bias\n",
    "            inputs = sigmoid_activate(inputs)\n",
    "            \n",
    "        inputs = np.matmul(self._outputs, inputs)\n",
    "        inputs = inputs.reshape(-1)\n",
    "        \n",
    "        \n",
    "        return softmax_activate(inputs)\n",
    "\n",
    "    def mutate(self):\n",
    "        new_chicken = NeuralNetwork(self._layers[0].shape[1],isACopy=True) #Create a new object.\n",
    "        \n",
    "        for l in self._layers: #We copy the layers.. but we consider a possible mutation.\n",
    "            random_mutation_probs = np.random.rand(l.shape[0], l.shape[1])\n",
    "            #We create a mask that we will add to the layer.\n",
    "            random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                             (np.random.rand()-0.5)/2, 0)\n",
    "            new_l = l + random_mutation_probs #we add he possible mutations\n",
    "            new_chicken._layers.append(new_l) #we affect the layer to the new snake.\n",
    "            \n",
    "            \n",
    "        for b in self._biases: #Same for biases\n",
    "            random_mutation_probs = np.random.rand(b.shape[0], 1)\n",
    "            random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                             (np.random.rand()-0.5)/2, 0)\n",
    "            new_l = b + random_mutation_probs\n",
    "            new_chicken._biases.append(new_l)\n",
    "    \n",
    "    \n",
    "        random_mutation_probs = np.random.rand(self._outputs.shape[0],self._outputs.shape[1])\n",
    "        random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                         (np.random.rand()-0.5)/2, 0)\n",
    "        \n",
    "        new_l = self._outputs + random_mutation_probs\n",
    "        new_chicken._outputs = new_l #Same for the output.\n",
    "        return new_chicken\n",
    "\n",
    "    def set_reward(self, r):\n",
    "        self._reward = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_saved = 0.1 #percentage of agents to be removed because they performance are too low\n",
    "chances_of_mutation = 1e-2 #Chance that a neuron mutates when a breeding occurs.\n",
    "a.sort(key=lambda agent: agent._reward, reverse=True) #We order our list based on reward.\n",
    "#for i in a:\n",
    "#   print(i._reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Worst score was \"+str(a[-1]._reward)+\"; best score was \"+str(a[0]._reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, observation_size, isACopy=False): #We specify the observation\n",
    "        self._layers = []\n",
    "        self._biases = [] #we implement the biases\n",
    "        self._rewards = 0 #Number of registered rewards.\n",
    "        if(not isACopy):\n",
    "           \n",
    "            for i in range(nb_layers):\n",
    "                entry_size = neurons if i != 0 else observation_size #First layer must match the input layer.\n",
    "                                                                    #Remember : The input layer is all the map, flattened.\n",
    "                #our weights values will be from -1 to 1.\n",
    "                self._layers.append(np.random.rand(neurons,entry_size)*2-1) #we initialize random values\n",
    "                self._biases.append(np.random.rand(neurons, 1)*2-1) #we initialize random values.\n",
    "\n",
    "            # TODO: change to 7\n",
    "            self._outputs = np.random.rand(5,neurons)*2-1 #Output layer must contain a total of 7 cells.\n",
    "            #We don't add it into self._layers because we want to activate it with a softmax.\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "       \n",
    "        inputs = np.zeros((len(inps[0]),len(inps)),dtype=float, order='C')\n",
    "        \n",
    "      \n",
    "        for i in range(len(inps)):\n",
    "            for j in range(len(inps[0])):\n",
    "                inputs[i][j] = inps[i][j][1]\n",
    "                \n",
    "        inputs = inputs.reshape((-1,1))\n",
    "        \n",
    "        for layer, bias in zip(self._layers, self._biases): #we zip the biases to the layer\n",
    "            print(layer)\n",
    "            print(inputs)\n",
    "            inputs = np.matmul(layer,inputs)\n",
    "            inputs = inputs+bias\n",
    "            inputs = sigmoid_activate(inputs)\n",
    "            \n",
    "        inputs = np.matmul(self._outputs, inputs) #(4,1)\n",
    "        inputs = inputs.reshape(-1) #Just a vector of 4 elements.\n",
    "        \n",
    "        \n",
    "        return softmax_activate(inputs)#Updated to softmax\n",
    "\n",
    "    def mutate(self):\n",
    "        new_agent = NeuralNetwork(self._layers[0].shape[1],isACopy=True) #Create a new object.\n",
    "        \n",
    "        for l in self._layers: #We copy the layers.. but we consider a possible mutation.\n",
    "            random_mutation_probs = np.random.rand(l.shape[0], l.shape[1])\n",
    "            #We create a mask that we will add to the layer.\n",
    "            random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                             (np.random.rand()-0.5)/2, 0)\n",
    "            new_l = l + random_mutation_probs #we add he possible mutations\n",
    "            new_agent._layers.append(new_l) #we affect the layer to the new snake.\n",
    "            \n",
    "            \n",
    "        for b in self._biases: #Same for biases\n",
    "            random_mutation_probs = np.random.rand(b.shape[0], 1)\n",
    "            random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                             (np.random.rand()-0.5)/2, 0)\n",
    "            new_l = b + random_mutation_probs\n",
    "            new_agent._biases.append(new_l)\n",
    "    \n",
    "    \n",
    "        random_mutation_probs = np.random.rand(self._outputs.shape[0],self._outputs.shape[1])\n",
    "        random_mutation_probs = np.where(random_mutation_probs < chances_of_mutation,\n",
    "                                         (np.random.rand()-0.5)/2, 0)\n",
    "        \n",
    "        new_l = self._outputs + random_mutation_probs\n",
    "        new_agent._outputs = new_l #Same for the output.\n",
    "        return new_agent\n",
    "        \n",
    "    \n",
    "    def set_reward(self, r): #We register the reward it got.\n",
    "        self._reward = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix error\n",
    "def simulation_reset(): #Useful when we change the code of the Neural Network... as actual snake won't be updated.\n",
    "    global a\n",
    "    \n",
    "    for i in a:\n",
    "        del(i) #Memory cleaning.\n",
    "        \n",
    "    a = []\n",
    "    for _ in range(agent_no):\n",
    "        S = NeuralNetwork(obs_size)\n",
    "        a.append(S)\n",
    "    print(\"agents: \",len(a))\n",
    "\n",
    "def run_global_simulation(display_tqdm = True, display_graph = False, track_best = True): #We create a function which gives a run.\n",
    "    global agents\n",
    "    rewards = []\n",
    "    \n",
    "    if(display_tqdm):\n",
    "        # Update jupyter\n",
    "        rewards, agents = simulation(agent_no, simulation_no, display_tqdm)\n",
    "    else:\n",
    "        rewards, agents = simulation(agent_no, simulation_no)\n",
    "    \n",
    "    if(display_graph):\n",
    "        pass\n",
    "        #plt.hist(rewards, bins=15);\n",
    "        #plt.show();\n",
    "    \n",
    "    agents.sort(key=lambda agent: agent._reward, reverse=True) #We order our list based on reward.\n",
    "    \n",
    "    if(track_best):\n",
    "        print(\"Best reward this time :\"+str(agents[0]._reward))\n",
    "        \n",
    "    return agents[0]._reward #Used for plotting.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_global_simulation(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(agents[0]._reward) # check for the best reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darwin_cleaner():#Will clean the farm from the bad species.\n",
    "    global agents #We will edit the variable from the function.\n",
    "    \n",
    "    qte_to_keep = int(0.2 * len(agents))\n",
    "    print(qte_to_keep)\n",
    "    new_agents = agents[:qte_to_keep] #The snakes we'll keep.\n",
    "    \n",
    "    new_species = []\n",
    "    for i in range(len(agents) - qte_to_keep):\n",
    "        parent_agent = new_agents[i%qte_to_keep]\n",
    "        new_agent = parent_agent.mutate()\n",
    "        new_species.append(new_agent)\n",
    "        \n",
    "    agents = new_agents + new_species\n",
    "#darwin_cleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5, -5, 10, -5, 0]\n"
     ]
    }
   ],
   "source": [
    "#print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-65f8270acedc>:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1+np.exp(-layer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "rewards = []\n",
    "for _ in range(15):\n",
    "    rewards.append(run_global_simulation(False, False, False))\n",
    "    darwin_cleaner()\n",
    "plt.plot(rewards);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255],\n",
       "        [  0,  10],\n",
       "        [100, 100],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[100, 100],\n",
       "        [100, 100],\n",
       "        [  0, 255],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[  0,  10],\n",
       "        [  0, 255],\n",
       "        [100, 100],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[101,   0],\n",
       "        [  0,   0],\n",
       "        [  0, 255],\n",
       "        [  0, 255]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255],\n",
       "        [  0,  10],\n",
       "        [100, 100],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[100, 100],\n",
       "        [100, 100],\n",
       "        [  0, 255],\n",
       "        [100, 100]],\n",
       "\n",
       "       [[  0,  10],\n",
       "        [  0, 255],\n",
       "        [100, 100],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[101,   0],\n",
       "        [  0,   0],\n",
       "        [  0, 255],\n",
       "        [  0, 255]]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[(0,10),(0,10),(100,100),(0,0)],[(100,100),(100,100),(0,0),(0,0)],[(0,10),(0,255),(100,100),(0,0)],[(101,0),(0,0),(0,255),(0,255)]]\n",
    "b = [[(0,0),(0,0),(100,100),(0,0)],[(100,100),(0,0),(0,255),(0,0)],[(0,10),(0,255),(100,100),(0,0)],[(101,0),(0,0),(0,255),(0,10)]]\n",
    "c = [[(0,10),(0,0),(100,100),(0,0)],[(0,0),(100,100),(0,255),(0,0)],[(0,0),(0,0),(100,100),(0,0)],[(101,0),(0,255),(0,255),(0,0)]]\n",
    "d = [[(0,0),(0,10),(0,0),(0,0)],[(100,100),(100,100),(0,255),(0,0)],[(0,10),(0,0),(0,0),(0,255)],[(101,0),(0,0),(0,255),(0,0)]]\n",
    "e = [[(0,255),(0,0),(100,100),(0,0)],[(100,100),(0,0),(0,255),(0,0)],[(0,10),(0,0),(100,100),(0,0)],[(101,0),(0,0),(0,255),(0,10)]]\n",
    "f = [[(0,0),(0,0),(0,255),(0,10)],[(0,0),(100,100),(0,255),(0,0)],[(0,0),(0,0),(100,100),(0,10)],[(101,0),(0,0),(0,255),(0,0)]]\n",
    "st = np.array([[(0,255),(0,10),(100,100),(0,0)],[(100,100),(100,100),(0,255),(100,100)],[(0,10),(0,255),(100,100),(0,10)],[(101,0),(0,0),(0,255),(0,255)]])\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 10), (0, 10), (100, 100)],\n",
       " [(100, 100), (100, 100)],\n",
       " [(0, 10), (0, 255), (100, 100)],\n",
       " [(101, 0), (0, 255), (0, 255)]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eliminate_empty(arr):\n",
    "    new_arr = []\n",
    "    for i in arr:\n",
    "        subarr = []\n",
    "        for j in i:\n",
    "            if j!=(0,0):\n",
    "                subarr.append(j)\n",
    "        new_arr.append(subarr)\n",
    "    return new_arr\n",
    "                \n",
    "x=eliminate_empty(a)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position(arr,n):\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr[i])):\n",
    "            if arr[i][j][0] == n:\n",
    "                return (i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent's position\n",
    "agent_pos=find_position(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obs_update(obs):\n",
    "    localisation = find_position(obs,101)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms = {\n",
    "\n",
    "            'The Attic' : {\n",
    "\n",
    "                  'down' : 'The Main Bedroom',\n",
    "                  'right': 'The Top Floor Door',\n",
    "                  'hidden': 'treasure',\n",
    "                  'state': 'open',\n",
    "                  'description' : ''\n",
    "            },\n",
    "\n",
    "            'The Top Floor Door' : {\n",
    "\n",
    "                  'right' : 'The Sunroom',\n",
    "                  'left': 'The Attic',\n",
    "                  'down':  'The First Floor Door',\n",
    "                  'state': 'locked', # can be changed\n",
    "                  'hidden':'',\n",
    "                  'description' : ''\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Sunroom' : {\n",
    "                  'right': 'The Balcony',\n",
    "                  'left': 'The Top Floor Door',\n",
    "                  'down': 'laundry',\n",
    "                  'hidden':'',\n",
    "                  'description' : 'You see an unlocked drawer next to the bed',\n",
    "                  'state': 'open',\n",
    "                  'item' : 'drawer'\n",
    "            },\n",
    "\n",
    "            'The Balcony' : {\n",
    "                  'left' : 'The Sunroom',\n",
    "                  'down': 'Guest Bedroom',\n",
    "                  'description':'',\n",
    "                  'state': 'open',\n",
    "                  'hidden':''\n",
    "            },\n",
    "\n",
    "            'The Main Bedroom' : {\n",
    "                'up': 'The Attic',\n",
    "                'down': 'The Living Room',\n",
    "                'right':'The First Floor Door',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden':'treasure'\n",
    "            },\n",
    "\n",
    "            'The First Floor Door' : {\n",
    "                'up': 'The Top Floor Door',\n",
    "                'down': 'The Ground Floor Hallway',\n",
    "                'right':'The Main Bedroom',\n",
    "                'left': 'The Laundry Room',\n",
    "                'state': 'locked',\n",
    "                'hidden':''\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Laundry Room' : {\n",
    "                'up': 'The Sunroom',\n",
    "                'down': 'The Dining Room',\n",
    "                'right':'The Guest Bedroom',\n",
    "                'left': 'The First Floor Door',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden':'treasure'\n",
    "            },\n",
    "\n",
    "            'The Guest Bedroom' : {\n",
    "                'up': 'The Balcony',\n",
    "                'down': 'The Kitchen',\n",
    "                'left': 'The Laundry Room',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'trap'\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Living Room' : {\n",
    "                'up': 'The Main Bedroom',\n",
    "                'down': 'The Basement Storge Room',\n",
    "                'right':'The Ground Floor Hallway',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden':''\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Ground Floor Hallway' : {\n",
    "                'up': 'The First Floor Door',\n",
    "                'down': 'The Game Room',\n",
    "                'right':'The Dining Room',\n",
    "                'left': 'The Living Room',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'treasure'\n",
    "            },\n",
    "\n",
    "            'The Dining Room' : {\n",
    "                'up': 'The Laundry Room',\n",
    "                'down': 'The Basement Door',\n",
    "                'right':'The Kitchen',\n",
    "                'left': 'The Ground Floor Hallway',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden':''\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Kitchen' : {\n",
    "                'up': 'The Guest Bedroom',\n",
    "                'down': 'The Garage',\n",
    "                'left': 'The Dining Room',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'treasure'\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Basement Storge Room' : {\n",
    "                'up': 'The Main Bedroom',\n",
    "                'right':'The Game Room',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'treasure'\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Game Room' : {\n",
    "                'up': 'The Ground Floor Hallway',\n",
    "                'right': 'The Basement Door',\n",
    "                'left': 'The Basement Storge Room',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'treasure'\n",
    "\n",
    "            },\n",
    "\n",
    "            'The Basement Door' : {\n",
    "                'up': 'The Dining Room',\n",
    "                'right': 'The Garage',\n",
    "                'left': 'The Game Room',\n",
    "                'state': 'locked',\n",
    "                'description':'',\n",
    "                'hidden':''\n",
    "\n",
    "            },\n",
    "            'The Garage' : {\n",
    "                'up': 'The Kitchen',\n",
    "                'left': 'The Basement Door',\n",
    "                'description':'',\n",
    "                'state': 'open',\n",
    "                'hidden': 'trap'\n",
    "\n",
    "            }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0., 255.,   0.],\n",
       "        [100., 100.,   0.],\n",
       "        [100., 100.,   0.],\n",
       "        [100., 100.,   0.]],\n",
       "\n",
       "       [[  0., 255.,   0.],\n",
       "        [100., 100.,   0.],\n",
       "        [  0., 255.,   0.],\n",
       "        [  0.,  10.,   0.]],\n",
       "\n",
       "       [[101.,   0.,   0.],\n",
       "        [  0., 255.,   0.],\n",
       "        [  0., 255.,   0.],\n",
       "        [  0., 255.,   0.]],\n",
       "\n",
       "       [[  0., 255.,   0.],\n",
       "        [  0., 255.,   0.],\n",
       "        [100., 100.,   0.],\n",
       "        [  0.,  10.,   0.]]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_converter(rooms_dict):\n",
    "    states = np.array([])\n",
    "   \n",
    "    for key, value in rooms_dict.items():\n",
    "\n",
    "        if key == 'The Living Room':\n",
    "            sub=np.array([101,0,0])\n",
    "\n",
    "        elif value['hidden'] == 'treasure':\n",
    "            sub=np.array([0,255,0])\n",
    "        elif value['hidden'] == 'trap':\n",
    "            sub=np.array([0,10,0])\n",
    "        elif value['state'] == 'locked':\n",
    "            sub=np.array([100,100,0])\n",
    "    \n",
    "        \n",
    "        states=np.append(states,sub)\n",
    "    states = states.reshape(4,4,3)\n",
    "    \n",
    "    \n",
    "    return states\n",
    "sta = state_converter(rooms)\n",
    "sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta[3][3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
